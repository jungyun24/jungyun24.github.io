---
layout: single
title: "Lecture 2"
categories: CS231n
tags: [CS231n, Image Classification, data driven, NN, Nearest Neighbor, Classifier, KNN, validation]
toc: true
author_profile: false
sidebar:
  nav: "docs"
---

<head>
  <style>
    table.dataframe {
      white-space: normal;
      width: 100%;
      height: 240px;
      display: block;
      overflow: auto;
      font-family: Arial, sans-serif;
      font-size: 0.9rem;
      line-height: 20px;
      text-align: center;
      border: 0px !important;
    }

    table.dataframe th {
      text-align: center;
      font-weight: bold;
      padding: 8px;
    }

    table.dataframe td {
      text-align: center;
      padding: 8px;
    }

    table.dataframe tr:hover {
      background: #b8d1f3; 
    }

    .output_prompt {
      overflow: auto;
      font-size: 0.9rem;
      line-height: 1.45;
      border-radius: 0.3rem;
      -webkit-overflow-scrolling: touch;
      padding: 0.8rem;
      margin-top: 0;
      margin-bottom: 15px;
      font: 1rem Consolas, "Liberation Mono", Menlo, Courier, monospace;
      color: $code-text-color;
      border: solid 1px $border-color;
      border-radius: 0.3rem;
      word-break: normal;
      white-space: pre;
    }

  .dataframe tbody tr th:only-of-type {
      vertical-align: middle;
  }

  .dataframe tbody tr th {
      vertical-align: top;
  }

  .dataframe thead th {
      text-align: center !important;
      padding: 8px;
  }

  .page__content p {
      margin: 0 0 0px !important;
  }

  .page__content p > strong {
    font-size: 0.8rem !important;
  }

  </style>
</head>


# Lecture 2

## Image Classification

- Computer Vision의 핵심 problems 중 하나

- Object detection, segmentation, Image captioning에 기여됨


### The problem : semantic gap

![](https://cs231n.github.io/assets/classify.png)

- image는 숫자로 구성된 3D array로 구성

- (width) x (height) x 3(color channels(RGB)) ex. 300x100x3


### Challenges

- `Viewpoint variation(시점 변화)` 하나의 object를 볼때 카메라의 위치나 방향에 따라 달라질 수 있음

- `Scale variation(크기 변화)` 크기의 변화가 많음(이미지 범위 뿐만이 아니라 실제크기도)

- `Deformation(변형)` 다양한 자세나 모양세를 가지고 있음

- `Occlusion(폐색)` 은폐, 은닉 ex)커튼에 숨은 고양이

- `Illumination conditions(조명)` 조명 효과에 따라 달라짐

- `Background clutter(배경 구분)` background와 식별이 어려울 수 있음

- `Intra-class variation(내부class의 다양성)` class가 비교적 광범위할 수 있음 ex)5마리 고양이 중 고양이 내에서 또 어떻게 구분?


![](https://cs231n.github.io/assets/challenges.jpeg)


### Attempts have been made


![](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/gg.png?raw=true)


image 내에서 feature를 알고리즘으로 구현  

어떤 방향으로 edge들이 구현되어 있는지  

**but 많은 한계...**


## Data-driven approach

- 사람이 직접 알고리즘을 만드는것이 아니라 데이터를 기반으로 model을 만들어 문제를 해결하고자 하는 방법

- Rule-based approach 방법보다 효과적

- 수많은 image와 label이 있는 dataset을 통해 model을 training(학습)

- 여러 데이터 소스를 식별 및 관리하여 고급 분석 모델을 구축할 수 있다.

![Rule-based approach vs. Data-driven approach](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/aa.jpg?raw=true)






```python
def predict(image):
    # ????
    return class_label
```

image classifier 알고리즘을 위와같이 정해진 hard coding으로 알고리즘을 만드는 것은 쉽지 않다.  

따라서 고안된 방법이 **data-driven approach**  



```python
def train(train_images, train_labels):
	# build a model for images -> labels...
    return model
   
def predict(model, test_images):
	# predict test_labels using the model...
    return test_labels
```

### 진행과정

1. image와 label로 구성된 dataset수집

2. 이 dataset에 대해서 image classifier 학습

3. test image set들에 대해서 학습을 시킨 image classifier를 evaluate


## Nearest Neighbor Classifier

- 사실상 아무도 사용하지 않음

- image classifier 문제에 대한 기본적인 접근 방법을 알 수 있음

- Train step : 모든 학습 데이터를 기억

- Predict step : 새로 입력된 이미지와 기존 학습 데이터를 비교하고 가장 유사한 이미지로 labeling

- Train set의 이미지 갯수가 N만큼 커진다면 Train/Test function의 속도는 `Train Time < Predict Time` 형태로 상황 추론이 더 빨라야 한다.


image classifier dataset(CIFAR-10)

![CIFAR-10](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/image.png?raw=true)



왼쪽 : CIFAR-10 dataset의 이미지 예시  

오른쪽 : 첫번째 열은 test image, 다음 열부터는 pixel-wise difference(픽셀 간 차이)에 따른 상위 10개의 NN  

  


training image와 test image를 비교하는 방식으로는 이미지 array의 각각의 값을 비교하고, 그 차이를 모두 더하는 것  

즉, 이미지 간의 distance를 구하는것이다.


### $ L1 $ distance 구하는 방법:

![](https://velog.velcdn.com/images/kgbkelvin/post/11773d74-7698-4262-a1df-e7ebdac5b129/image.png)

![](https://velog.velcdn.com/images/kgbkelvin/post/ed298eaa-1832-4740-92ac-c60a729a56c7/image.png)

만약 두 장의 image가 완전히 같다면 결과는 0이 될 것이고, 많이 다르면 결과는 클 것이다.


### Nearest Neighbor Classifier 구현



- CIFAR-10 data를 메모리로 불러와 4개의 array에 저장  

(각각은 training data와 그 label, test data와 그 label)

- 아래 코드에 Xtr(크기 50,000 x 32 x 32 x 3)은 트레이닝 셋의 모든 이미지를 저장하고 1차원 배열인 Ytr(길이 50,000)은 트레이닝 데이터의 라벨(0부터 9까지)을 저장



```python
(Xtr, Ytr), (Xte, Yte) = cifar10.load_data() # 제공되는 함수 X는 (32*32*3)이미지 형식, y는 class index
# 모든 이미지가 1차원 배열로 저장된다.
# shape[0]은 행의 갯수 반환, reshape(x, y)은 x, y로 다시 재배열

Xtr_rows = Xtr.reshape(Xtr.shape[0], 32 * 32 * 3) # Xtr_rows는 50000 x 3072 크기의 배열.
Xte_rows = Xte.reshape(Xte.shape[0], 32 * 32 * 3) # Xte_rows는 10000 x 3072 크기의 배열.
```

일반적으로 평가 기준은 **accuracy**를 사용  

앞으로 만들어볼 모든 분류기는 공통적인 API를 갖는다.  

데이터(X)와 데이터가 실제로 속하는 라벨(y)을 입력으로 받는 train(X,y) 형태의 함수  

  

내부적으로, 이 함수는 label들을 활용하여 어떤 model을 만들어야 하고, 그 값들이 data로부터 어떻게 예측될 수 있는지를 알아야 한다.  

그 이후에는 새로운 data로부터 label을 예측하는 predict(X) 형태의 함수가 있다.  

(물론, 아직은 실제 classifier는 빠져있다)  

  

$L1$ distance를 이용한 간단한 Nearest Neighbor Classifier이다.



```python
import numpy as np

class NearestNeighbor(object):
    def __init__(self):
        pass
    
    def train(self, X, y):
        """ X is N x D where each row is an example. Y is 1-dimension of size N """
        # nearest neighbor 분류기는 단순히 모든 학습 데이터를 기억해둔다.
        self.Xtr = X
        self.ytr = y
    
    def predict(self, X):
        """ X is N x D where each row is an example we wish to predict label for """
        num_test = X.shape[0]
        # 출력 type과 입력 type이 갖게 되도록 확인해준다.
        Ypred = np.zeros(num_test, dtype = self.ytr.dtype)
        
        # loop over all test rows
        for i in range(num_test):
        # i번째 테스트 이미지와 가장 가까운 학습 이미지를
        # L1 거리(절대값 차의 총합)를 이용하여 찾는다.
            distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)
            min_index = np.argmin(distances) # 가장 작은 distance를 갖는 인덱스를 찾는다.
            Ypred[i] = self.ytr[min_index] # 가장 가까운 이웃의 라벨로 예측

        return Ypred
```

위 코드를 사용해서 테스트셋에 대한 성능을 평가한 결과 38.6 % 정도의 성능을 보인다. 우선, 임의로 찍은 수치 (10 %) 보다 성능이 좋기 때문에 모델을 만드는데 큰 노력을 들이지 않았다는 점을 감안해 괜찮은 수치이다. 하지만 state-of-the-art 인 Convolutional Neural Network 기반 모델의 성능 (95 %) 과 비교하면 매우 낮다. 


### L2 distance

Distance selection vector 간의 거리를 계산하는 방법으로 기하학적으로 두 vector 간의 Euclidian distance를 계산하는 것으로 해석할 수 있는 $L2$ distance를 사용할 수 있다.  

![image.png](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTeib0zGkQ7szQi4hLk_aAQO3zPOCH93nsDzw&usqp=CAU)




```python
distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = 1))
```

위 코드에서 한줄만 바꾸면 된다.


### L1 L2 distance 의 차이



![](https://velog.velcdn.com/images/dongho5041/post/688586ee-3334-413a-ba20-fa4af3c1515e/image.png)

- L1 distance : 픽셀 간 차이 절대값의 합

    - 좌표 시스템 종류에 따라 영향이 크다

- L2 (Euclidean) distance : 제곱합의 제곱근

    - 좌표계와 연관이 없다

- 특정 벡터가 개별적인 의미를 가지고 있다면(ex. 키, 몸무게) L1 Distance를, 일반적인 벡터 요소들의 의미를 모르거나 의미가 별로 없을 때는 L2 Distance를 사용한다.


## K - Nearest Neighbor

- Nearest Neighbor은 단점이 많은 알고리즘이다.

    - 단 하나의 label만 prediction에서 고려하기에 stability가 떨어진다.(즉, 성능 저하)

- 이를 보완하기 위해 KNN을 활용

- test(predict) 단계에서 input과 가까운 순으로 총 k개의 data의 label을 구한 후, 가장 빈번하게 나오는 label로 예측하는 방법

(voting : 여러개로부터 가장 빈번하게 나오는 것을 예측 결과로 하는것)



![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F990B12355E29CED902)

[참고자료] : http://vision.stanford.edu/teaching/cs231n-demos/knn/

### 장점

- NN에는 outlier를 중심으로 decision boundary(섬처럼 만들어진 곳)가 생기지만 KNN의 경우, **이상치에 더 둔감**  

(NN의 경우, outlier에 민감하기 때문에 training data에 국한된 규칙을 배울 가능성이 높다)  

(KNN의 경우, unseen data 대한 성능 (generalization)이 높을 것이다.) 



>**unseen data를 올바르게 예측하는 것이 ML(Machine Learning) 방법을 사용한 predict modeling의 주요목적**이다.  

  

KNN을 실제로 사용할 때는 한가지 고려 상항은 **k를 어떻게 정하냐**이다.  

k가 높을 수록 그만큼 test stage에서의 계산량이 매우 많아지는 단점이 있다.  


## Hyperparameter

종종 어떤 값/설정을 선택해야 할지 명확하지 않은 경우가 많다.



- k의 값을 어떻게 설정하는 것이 가장 좋은 성능일까?

- 어떤 distance function을 이용해야 할까?



**hyperparameter를 수정할 목적으로 test set을 절대 사용해서는 안된다.**

> - **ML 알고리즘을 만들 때, test set을 알고리즘 테스트에 딱 한번 외에는 절대 사용해서는 안될 소중한 자원이라 생각해야 한다.**

  - test set에 맞추기 위해 hyperparameter를 수정시, 실제 model을 배치했을때, 성능이 감소할 수 있다.



>트레이닝셋을 트레이닝셋과 검증셋으로 나눈 후, 검증셋을 사용하여 모든 하이퍼파라미터를 조정합니다. 마지막에 테스트셋에 대해 단 한 번 실행한 결과를 최종 성능으로 보고합니다.


(CIFAR-10에서 validation set이 어떻게 표현되는지)



```python
class NearestNeighbor(object):
    def __init__(self):
        pass
    
    def train(self, X, y):
        """ X is N x D where each row is an example. Y is 1-dimension of size N """
        # nearest neighbor 분류기는 단순히 모든 학습 데이터를 기억해둔다.
        self.Xtr = X
        self.ytr = y
    
    def predict(self, X):
        """ X is N x D where each row is an example we wish to predict label for """
        num_test = X.shape[0]
        # 출력 type과 입력 type이 갖게 되도록 확인해준다.
        Ypred = np.zeros(num_test, dtype = self.ytr.dtype)
        
        # loop over all test rows
        for i in range(num_test):
        # i번째 테스트 이미지와 가장 가까운 학습 이미지를
        # L1 거리(절대값 차의 총합)를 이용하여 찾는다.
            distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)
            min_index = np.argmin(distances) # 가장 작은 distance를 갖는 인덱스를 찾는다.
            Ypred[i] = self.ytr[min_index] # 가장 가까운 이웃의 라벨로 예측

        return Ypred
```

![](https://velog.velcdn.com/images/eunjnnn/post/9b91500f-38a3-428c-8b05-412093990593/image.png)

`Idea 1`

- 전체 데이터에 대한 최적의 hyperparameter를 선택합니다.

- 단점 : K=1일 때 트레이닝 데이터에 항상 완벽하게 동작합니다.  



`Idea 2`

- 전체 data를 training/test data로 분할하고, test data에 대한 최적의 hyperparameter를 선택합니다.

- 단점 : 새로운 데이터에 대해서 알고리즘이 어떤 성능을 보일지 알 수 없습니다.  



`idea 3`

- 전체 데이터를 fold로 분할한 후, 각 fold를 번갈아가며 validation하고 그 결과를 평균 냅니다.

- 작은 데이터셋에는 유용한 방식이지만, 딥러닝에서 그리 자주 사용되지는 않습니다.


### Cross-validation

- training data와 validation data의 크기가 작을 경우

    - hyperparameter 조정을 위한 보다 정교한 방법인 `corss-validation`사용

- 서로 다른 validation set에 대해 반복하고 이들 전체에 걸쳐 성능을 평균함으로써 특징 k값이 얼마나 좋은 성능을 보이는지에 대한 더 좋은 결과를 얻을 수 있다.

- (ex) 5-fold cross-validation에서는 training data를 5개의 동일한 크기로 나누고, 그 중 4개를 학습에 사용하고, 1개는 validation을 위해 사용, 그 후 validation fold를 바꾸어 가며 반복하고, 성능을 평가하며, 모든 fold에 걸쳐 성능을 평균화한다.



![](https://sangminwoo.github.io/img/cs231n/lecture2/2.4.1.cvplot.png)



*parameter k에 대한 5-fold cross validation의 예*    

*- k의 각 값에 대해 4fold씩 학습 후 5번째 validation*  

*- 따라서, 각 k에 대한 validation fold에서 5개의 accuracy를 알 수 있다.*  

*- k =7이 가장 잘작용함을 알 수 있다.*


**In practice**

- 실전에서 교차검증은 계산적으로 cost가 많이 든다.

    - single validation split을 할 때는, 선호하지 않는다.

- 일반적으로 training data의 50%~90%를 학습에 사용, 나머지는 validation에 사용

  (hyperparameter의 개수가 많은 경우, 더 큰 validation split을 사용하는 것이 선호됨)


![](https://sangminwoo.github.io/img/cs231n/lecture2/2.4.2.crossval.jpeg)

*일반적인 데이터 분할(data split)을 보여줍니다. 트레이닝셋과 테스트셋이 주어지고, 트레이닝셋은 fold(여기서는 5 fold)로 나뉩니다. fold 1-4가 트레이닝셋이 되고, fold 5(노란색)는 validation fold가 되어 하이퍼파라미터를 조정하는 데 사용됩니다. 교차 검증은 한 걸음 더 나아가서 fold 1-5에서 validation fold를 바꾸어가며 반복합니다. 이를 두고 5-fold cross-validation이라고 부릅니다. 모델이 학습을 완료하고 모든 최상의 하이퍼 파라미터가 결정되면, 모델은 테스트 데이터(빨간색)에서 단 한 번 평가됩니다.*


### Pros and Cons of Nearest Neighbor classifier

Pros

- 적용과 이해가 매우 간단

- classifier는 training data를 저장하고 index하는데만 필요하므로 training하는데 시간이 걸리지 않는다



Cons

- test data를 분류하려면 모든 training data를 비교해야 하기 때문에 test 시간에 어마어마한 계산 cost을 지불해야 한다.

(test 시간 효율을 학습 시간의 효율보다 더 많이 신경쓰기 때문)


Deep Neural Networks에서는 이 trade off를 반대의 방식이 된다.  

학습에 매우 높은 cost를 지불하지만 학습이 끝나면 새로운 data를 분류하는 것은 매우 적은 cost로도 가능  

이러한 방식이 실제로 훨씬 더 바람직


# 요약

- 단일 카테고리의 라벨이 붙은 이미지셋이 주어졌을 때, 이미지 분류의 문제점을 알아보았습니다. 또한 새로운 테스트셋에 대한 카테고리를 예측하고 그 정확도를 측정하는 방법을 알아보았습니다.

- Nearest Neighbor Classifier이라 불리는 단순한 분류기를 알아보았습니다. 그리고 분류기와 관련있는 여러 하이퍼파라미터(k의 값, 사용하는 distance의 종류)의 예를 보았고, 이를 선택하는 명료한 방법이 없다는 것도 알았습니다.

-  하이퍼파라미터를 설정하는 바람직한 방법은 트레이닝셋을 두 개로 나누는 것 - 트레이닝셋과 가짜 테스트셋(검증셋) - 입니다. 그리고 여러 하이퍼파라미터들을 바꿔가며 검증셋에 대해 가장 좋은 결과를 보인 값을 선택하는 방법입니다.

- 트레이닝셋이 부족한게 문제라면, cross-validation 방법을 사용하는 것을 고려해볼 수 있습니다. 이는 어떤 하이퍼파라미터가 가장 좋은 결과를 보이는지에 대한 noise를 줄여줍니다.

- 가장 좋은 결과를 보이는 하이퍼파라미터를 찾았다면, 이를 고정하고 실제 테스트셋로 단 한번의 평가(evaluation)를 진행합니다.

- Nearest Neighbor는 CIFAR-10을 기준으로 약 40%의 정확도를 보였습니다. 구현하기는 쉽지만 모든 트레이닝셋을 저장해야하며 테스트 이미지에 대해서 평가를 할 때 많은 비용이 듭니다.

- 마지막으로, raw pixel에 L1 또는 L2 distance를 사용하는것은 부적절하다는것을 알 수 있습니다. 이는 distance가 이미지의 내용적 의미(semantic content)보다는 배경이나 색 분포에 더 관련이 있기 때문입니다.

