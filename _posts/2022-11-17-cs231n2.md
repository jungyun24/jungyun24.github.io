---
layout: single
title: "Lecture 2 : Image Classification"
categories: CS231n
tags: [stanford, lecture, review, CS231n, Image Classification, computer vision]
toc: true
author_profile: false
sidebar:
  nav: "docs"
---
# Lecture 2 | Image Classification
<iframe width="560" height="315" src="https://www.youtube.com/embed/OoUX-nOEjG0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

***
## Assignment 1
![](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/cs231n/l2/1f84d1b08f70417dcaf15463d867e54eBPtTa74reD6uEqs2-2.jpg?raw=true)
   
과제는 Python 또는 Numpy를 사용합니다.   
   
## Image Classification
![](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/cs231n/l2/1f84d1b08f70417dcaf15463d867e54eBPtTa74reD6uEqs2-5.jpg?raw=true)
   
지난 강의에서 computer vision의 핵심 작업인 image classification에 대해 이야기했습니다.   
"image classification을 정확히 어떻게 수행합니까?"   
   
좀 더 구체적으로 말하면,   
image classification을 할때 system은 input image를 받습니다.(Ex. 고양이)   
system은 미리 결정된 categories 또는 label의 set을 인식합니다.   
(Ex. 고정된 categories label로는 비행기, 개, 고양이 또는 트럭 등이 있고 컴퓨터가 할 일은 이들 중 하나를 할당하는 것)    
이것은 machine에게 정말 매우 어려운 작업입니다.   
   
![](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/cs231n/l2/1f84d1b08f70417dcaf15463d867e54eBPtTa74reD6uEqs2-6.jpg?raw=true)
   
따라서, 실제로 컴퓨터가 이 image를 볼때 무엇을 보는지 깊게 생각해보면 여러분이 고양이를 볼 때 보는 고양이에 대한 holistic(전체론적) idea를 확실히 얻지 못합니다.   
그리고 컴퓨터는 실제로 image를 이 커다란 grid of numbers(숫자 격자)로 표현하고 있습니다.   
따라서 image는 800x600 pixels정도일 수 있습니다.   
컴퓨터에게 이것은 거대한 grid of numbers에 불과합니다.   
그리고 이것에서 고양이다움을 distill(추출)하는 것은 매우 어렵습니다.   
예를 들어, 수천 개의 거대한 array 또는 무엇이든 매우 다양한 numbers입니다.   
그래서 우리는 이 문제를 semantic gap이라고 부릅니다.   
고양이에 대한 이 idea 또는 고양이에 대한 이 label은 우리가 image에 할당하는 semantic label입니다.   
   
![](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/cs231n/l2/1f84d1b08f70417dcaf15463d867e54eBPtTa74reD6uEqs2-7.jpg?raw=true)
   
고양이의 semantic idea와 컴퓨터가 실제로 보고 있는 이러한 pixel 값 사이에는 엄청난 차이가 있습니다.   
그리고 이것은 정말 어려운 문제입니다.   
picture을 아주 작고 subtle(미묘한) 방식으로 변경하여 이 pixel grid를 완전히 변할 수 있기 때문입니다.   
예를 들어, 우리가 고양이를 잡았는데 고양이가 가만히 앉아 꿈틀거리지도 않고 근육 하나도 움직이지 않는다면 절대 일어나지 않을 일이지만 우리는 카메라를 반대쪽으로 옮겼습니다. 그러면 giant grid of numbers에서 모든 single grid, 모든 single pixel은 완전히 달라집니다.   
하지만 여전히 같은 고양이를 나타내고 있습니다.
   
따라서 우리의 algorithm은 이에 robust해야 합니다.   
   
![](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/cs231n/l2/1f84d1b08f70417dcaf15463d867e54eBPtTa74reD6uEqs2-8.jpg?raw=true)
   
그러나 viewpoint만이 문제가 아니라 또 다른 문제는 illumination입니다.   
scene에서는 다양한 lighting 조건이 있을 수 있습니다.   
매우 어둡고 moody한 scene 또는 매우 밝고 햇빛이 비치는 scene과 같이 어디서 고양이가 나타나든 여전히 고양이이며 우리의 algorithm은 이에 대해 robust해야 합니다.   
   
![](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/cs231n/l2/1f84d1b08f70417dcaf15463d867e54eBPtTa74reD6uEqs2-9.jpg?raw=true)   
   
Object도 deform(변형)될 수 있습니다.   
아마도 고양이는 밖에서 볼수 있는 동물 중 deformable한 동물에 속한다고 생각합니다.   
따라서 고양이는 정말 다양하게 다른 poses와 positions을 취할 수 있습니다.   
그리고 우리의 algorithm은 이러한 다양한 종류의 transforms에 robust해야합니다.   
   

![](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/cs231n/l2/1f84d1b08f70417dcaf15463d867e54eBPtTa74reD6uEqs2-10.jpg?raw=true)  
   
또한 occlustion의 문제가 있을 수 있습니다.   
예를 들어 고양이의 일부만 볼 수 있습니다.   
예를 들어 얼굴만 보이거나 이 극단적인 예에서는 소파 쿠션 아래에서 꼬리만 볼 수 있습니다.   
  
그러나 이러한 경우 사람은 고양이라는 것을 깨닫는 것은 매우 쉽고 여전히 이러한 이미지를 고양이로 인식합니다.   
   
그리고 이것은 우리의 algorithm이 robust해야 하는 것이기도 합니다.   
   
![](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/cs231n/l2/1f84d1b08f70417dcaf15463d867e54eBPtTa74reD6uEqs2-11.jpg?raw=true)  
   
background clutter 문제도 있을 수 있습니다.   
고양이의 foreground object는 실제로 backgound와 appearance(모양)이 매우 유사하게 보일 수 있습니다.   
그리고 이것은 우리가 처리해야 할 또 다른 것입니다.   
   

![](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/cs231n/l2/1f84d1b08f70417dcaf15463d867e54eBPtTa74reD6uEqs2-12.jpg?raw=true)  
   
class 내 variation 문제도 있습니다. 고양이다움의 한 가지 개념이 실제로는 다양한 visual appearances에 걸쳐 있다는 것입니다.   
그리고 고양이는 shapes 그리고 sizes, colors, ages가 다를 수 있습니다.   
우리의 algorithm은 이러한 모든 이 다른 variations를 처리해야합니다.   
그래서 이것은 실제로 매우 어렵습니다.   
   
![](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/cs231n/l2/1f84d1b08f70417dcaf15463d867e54eBPtTa74reD6uEqs2-13.jpg?raw=true)  
   
image classifier를 작성하기 위한 API가 무엇인지 생각해보면 여러분은 앉아서 이렇게 python으로 method를 작성하려고 시도 할 수 있습니다. image를 가져와 결국 이 class label을 뱉어 고양이나 개 또는 기타 등등을 말하고 싶은 곳입니다.   
이것을 할 수 있는 확실한 방법은 없습니다.   
algorithm 수업을 듣고있고 task가 숫자를 정렬하거나 convex hull을 계산하는 것 또는 심지어 RSA암호화와 같은 작업을 수행하는 것이라면 algorithm을 작성하고 필요한 모든 단계를 열거 할 수 있습니다.   
   
그러나 우리가 물체를 인식하거나 고양이 도는 image를 인식하려고 할때 이러한 물체를 인식하는 방법에 대해 직관적으로 이해할 수 있는 명확하고 명시적인 algorithm이 없습니다.   
만약 여러분이 생각해본다면, 만약 여러분이 programming 첫날이고 여러분이 앉아서 이 function을 작성해야 한다면, 대부분의 사람들이 곤경에 처할 것입니다.   

![](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/cs231n/l2/1f84d1b08f70417dcaf15463d867e54eBPtTa74reD6uEqs2-14.jpg?raw=true) 
   
즉, 사람들은 다양한 동물을 인식하기 위해 일종의 고급 coding 규칙을 작성하려고 명시적으로 시도했습니다.    
그래서 우리는 지난 강의에서 Hubel과 Wiesel의 edge가 visual recognition과 관련하여 매우 중요하다는 것을 알고 있습니다.  
그러나 이것은 잘 작동하지 않는 것으로 밝혀졌습니다.   
- super brittle합니다.
- 만약 다른 object category로 다시 시작하고 싶다면 처음부터 다시 시작해야 합니다.   
   
따라서 이것은 실제로 매우 확장 가능한 접근 방식이 아닙니다.   
우리는 세계의 모든 다양한 object에 대해 훨씬 더 자연스럽게 확장되는 이러한 recognition tasks를 위한 algorithm 또는 method를 제시하고자 합니다.   

![](https://github.com/jungyun24/jungyun24.github.io/blob/master/_image/cs231n/l2/1f84d1b08f70417dcaf15463d867e54eBPtTa74reD6uEqs2-15.jpg?raw=true) 
   